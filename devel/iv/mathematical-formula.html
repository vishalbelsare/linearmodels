

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  
  <!-- Licensed under the Apache 2.0 License -->
  <link rel="stylesheet" type="text/css" href="../_static/fonts/open-sans/stylesheet.css" />
  <!-- Licensed under the SIL Open Font License -->
  <link rel="stylesheet" type="text/css" href="../_static/fonts/source-serif-pro/source-serif-pro.css" />
  <link rel="stylesheet" type="text/css" href="../_static/css/bootstrap.min.css" />
  <link rel="stylesheet" type="text/css" href="../_static/css/bootstrap-theme.min.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
    <title>Formulas and Mathematical Detail &#8212; linearmodels 3.5+15.gd85af6a documentation</title>
    <link rel="stylesheet" href="../_static/guzzle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '3.5+15.gd85af6a',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Panel Data Model Estimation" href="../panel/index.html" />
    <link rel="prev" title="GMM Weight and Covariance Estimation" href="gmm.html" />
  
  
   

  <link rel="stylesheet" href="../_static/css/overrides.css" type="text/css" />

  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../panel/index.html" title="Panel Data Model Estimation"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="gmm.html" title="GMM Weight and Covariance Estimation"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">linearmodels 3.5+15.gd85af6a documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Instrumental Variable Estimation</a> &#187;</li> 
      </ul>
    </div>
    <div class="container-wrapper">

      <div id="mobile-toggle">
        <a href="#"><span class="glyphicon glyphicon-align-justify" aria-hidden="true"></span></a>
      </div>
  <div id="left-column">
    <div class="sphinxsidebar">
        <a href="
    ../index.html" class="text-logo">linearmodels 3.5 (+15, gd85af6a)</a>
        
<div class="sidebar-block">
  <div class="sidebar-wrapper">
    <h2>Table Of Contents</h2>
  </div>
  <div class="sidebar-toc">
    
    
      <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Instrumental Variable Estimation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples/basic-examples.html">Basic Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples/advanced-examples.html">Further Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples/using-formulas.html">Using formulas to specify models</a></li>
<li class="toctree-l2"><a class="reference internal" href="reference.html">Module Reference</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Formulas and Mathematical Detail</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../panel/index.html">Panel Data Model Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asset-pricing/index.html">Linear Factor Models for Asset Pricing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../system/index.html">System Regression Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utility.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plan.html">Module Plans</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changes.html">Change Log</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References</a></li>
</ul>

    
  </div>
</div>
        
<div class="sidebar-block">
  <div class="sidebar-wrapper">
    <div id="main-search">
      <form class="form-inline" action="../search.html" method="GET" role="form">
        <div class="input-group">
          <input name="q" type="text" class="form-control" placeholder="Search...">
        </div>
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div>
    </div>
  </div>
        <div id="right-column">
          
          <div role="navigation" aria-label="breadcrumbs navigation">
            <ol class="breadcrumb">
              <li><a href="../index.html">Docs</a></li>
              
                <li><a href="index.html">Instrumental Variable Estimation</a></li>
              
              <li>Formulas and Mathematical Detail</li>
            </ol>
          </div>
          
          <div class="document clearer body">
            
  <div class="section" id="formulas-and-mathematical-detail">
<span id="iv-mathematical-notation"></span><h1>Formulas and Mathematical Detail<a class="headerlink" href="#formulas-and-mathematical-detail" title="Permalink to this headline">¶</a></h1>
<div class="section" id="notation">
<h2>Notation<a class="headerlink" href="#notation" title="Permalink to this headline">¶</a></h2>
<p>Interest is in recovering the parameter vector from the model</p>
<div class="math">
\[\begin{aligned}
y_{i} &amp; =\beta^{\prime}x_{i}+\epsilon_{i}\end{aligned}\]</div>
<p>where <span class="math">\(\beta\)</span> is <span class="math">\(k\)</span> by 1, <span class="math">\(x_{i}\)</span> is a <span class="math">\(k\)</span> by 1
vector of observable variables and <span class="math">\(\epsilon_{i}\)</span> is a scalar
error. <span class="math">\(x_{i}\)</span> can be separated in two types of variables. The
<span class="math">\(k_{1}\)</span> by 1 set of variables <span class="math">\(x_{1i}\)</span> are exogenous
regressors in the sense that <span class="math">\(E\left[x_{1i}\epsilon_{i}\right]=0\)</span>.
The <span class="math">\(k_{2}\)</span> by 1 variables <span class="math">\(x_{2i}\)</span> are endogenous. A set of
<span class="math">\(p\)</span> instruments is available that satisfy the requirements for
validity where <span class="math">\(p\geq k_{2}\)</span>. The extended model can be written as</p>
<div class="math">
\[\begin{split}\begin{aligned}
y_{i} &amp; =\underset{\textrm{exogenous}}{\underbrace{\beta_{1}^{\prime}x_{1i}}}+\underset{\textrm{endogenous}}{\underbrace{\beta_{2}^{\prime}x_{2i}}}+\epsilon_{i}\\
x_{2i} &amp; =\underset{\textrm{exogenous}}{\underbrace{\gamma_{1}^{\prime}z_{1i}}}+\underset{\textrm{instruments}}{\underbrace{\gamma_{2}^{\prime}z_{2i}}}+u_{i}\end{aligned}\end{split}\]</div>
<p>The model can be expressed compactly</p>
<div class="math">
\[\begin{split}\begin{aligned}
Y &amp; =X_{1}\beta_{1}+X_{2}\beta_{1}+\epsilon=X\beta+\epsilon\\
X_{2} &amp; =Z_{1}\gamma_{1}+Z_{2}\gamma_{2}+u=Z\gamma+u\end{aligned}\end{split}\]</div>
<p>The vector of instruments <span class="math">\(z_{i}\)</span> is <span class="math">\(p\)</span> by 1. There are
<span class="math">\(n\)</span> observations for all variables. <span class="math">\(k_{c}=1\)</span> if the model
contains a constant (either explicit or implicit, i.e., including all
categories of a dummy variable). The constant, if included, is in
<span class="math">\(x_{1i}\)</span>. <span class="math">\(X\)</span> is the <span class="math">\(n\)</span> by <span class="math">\(k\)</span> matrix if
regressors where row <span class="math">\(i\)</span> of <span class="math">\(X\)</span> is <span class="math">\(x_{i}^{\prime}\)</span>.
<span class="math">\(X\)</span> can be partitioned into <span class="math">\(\left[X_{1}\;X_{2}\right]\)</span>.
<span class="math">\(Z\)</span> is the <span class="math">\(n\)</span> by <span class="math">\(p\)</span> matrix of instruments. The
vector <span class="math">\(y\)</span> is <span class="math">\(n\)</span> by 1. Projection matrices for <span class="math">\(X\)</span> is
defined <span class="math">\(P_{X}=X\left(X^{\prime}X\right)^{-1}X^{\prime}\)</span>. The
projection matrix for <span class="math">\(Z\)</span> is similarly defined only using
<span class="math">\(Z\)</span>. The annihilator matrix for <span class="math">\(X\)</span> is
<span class="math">\(M_{X}=I-P_{X}\)</span>.</p>
</div>
<div class="section" id="parameter-estimation">
<h2>Parameter Estimation<a class="headerlink" href="#parameter-estimation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="two-stage-least-squares-2sls">
<h3>Two-stage Least Squares (2SLS)<a class="headerlink" href="#two-stage-least-squares-2sls" title="Permalink to this headline">¶</a></h3>
<p>The 2SLS estimator is</p>
<div class="math">
\[\begin{aligned}
\hat{\beta}_{2SLS} &amp; =\left(X^{\prime}P_{Z}X\right)^{-1}\left(X^{\prime}P_{Z}y\right)\end{aligned}\]</div>
</div>
<div class="section" id="limited-information-maximum-likelihood-and-k-class-estimators">
<h3>Limited Information Maximum Likelihood and k-class Estimators<a class="headerlink" href="#limited-information-maximum-likelihood-and-k-class-estimators" title="Permalink to this headline">¶</a></h3>
<p>The LIML or other k-class estimator is</p>
<div class="math">
\[\begin{aligned}
\hat{\beta}_{\kappa} &amp; =\left(X^{\prime}\left(I-\kappa M_{Z}\right)X\right)^{-1}\left(X^{\prime}\left(I-\kappa M_{Z}\right)y\right)\end{aligned}\]</div>
<p>where <span class="math">\(\kappa\)</span> is the parameter of the class. When
<span class="math">\(\kappa=1\)</span> the 2SLS estimator is recovered. When <span class="math">\(\kappa=0\)</span>,
the OLS estimator is recovered. The LIML estimator is recovered when
<span class="math">\(\kappa\)</span> set to</p>
<div class="math">
\[\hat{\kappa}=\min\mathrm{eig\left[\left(W^{\prime}M_{Z}W\right)^{-\frac{1}{2}}\left(W^{\prime}M_{X_{1}}W\right)\left(W^{\prime}M_{Z}W\right)^{-\frac{1}{2}}\right]}\]</div>
<p>where <span class="math">\(W=\left[y\:X_{2}\right]\)</span> and <span class="math">\(\mathrm{eig}\)</span> returns
the eigenvalues.</p>
</div>
<div class="section" id="generalized-method-of-moments-gmm">
<h3>Generalized Method of Moments (GMM)<a class="headerlink" href="#generalized-method-of-moments-gmm" title="Permalink to this headline">¶</a></h3>
<p>The GMM estimator is defined as</p>
<div class="math">
\[\begin{aligned}
\hat{\beta}_{GMM} &amp; =\left(X^{\prime}ZWZ^{\prime}X\right)^{-1}\left(X^{\prime}ZWZ^{\prime}y\right)\end{aligned}\]</div>
<p>where <span class="math">\(W\)</span> is a positive definite weighting matrix.</p>
</div>
<div class="section" id="continuously-updating-generalized-method-of-moments-gmm-cue">
<h3>Continuously Updating Generalized Method of Moments (GMM-CUE)<a class="headerlink" href="#continuously-updating-generalized-method-of-moments-gmm-cue" title="Permalink to this headline">¶</a></h3>
<p>The continuously updating GMM estimator solves the minimization problem</p>
<div class="math">
\[\min_{\beta}n\bar{g}\left(\beta\right)^{\prime}W\left(\beta\right)^{-1}\bar{g}\left(\beta\right)\]</div>
<p>where
<span class="math">\(\bar{g}\left(\beta\right)=n^{-1}\sum_{i=1}^{n}z_{i}\hat{\epsilon}_{i}\)</span>
and <span class="math">\(\hat{\epsilon}_{i}=y_{i}-x_{i}\beta\)</span>. Unlike standard GMM,
the weight matrix, <span class="math">\(W\)</span> directly depends on the model parameters
<span class="math">\(\beta\)</span> and so it is not possible to use a closed form estimator.</p>
</div>
</div>
<div class="section" id="basic-statistics">
<h2>Basic Statistics<a class="headerlink" href="#basic-statistics" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(\hat{\epsilon}=y-X\hat{\beta}\)</span>. The residual sum of squares
(RSS) is <span class="math">\(\hat{\epsilon}^{\prime}\hat{\epsilon}\)</span>, the model sum of
squares (MSS) is <span class="math">\(\hat{\beta}^{\prime}X^{\prime}X\hat{\beta}\)</span> and
the total sum of squares (TSS) is
<span class="math">\(\left(y-k_{c}\bar{y}\right)^{\prime}\left(y-k_{c}\bar{y}\right)^{\prime}\)</span>where
<span class="math">\(\bar{y}\)</span> is the sample average of <span class="math">\(y\)</span>. The model
<span class="math">\(R^{2}\)</span>is defined</p>
<div class="math">
\[\begin{aligned}
R^{2} &amp; =1-\frac{\hat{\epsilon}^{\prime}\hat{\epsilon}}{\left(y-k_{c}\bar{y}\right)^{\prime}\left(y-k_{c}\bar{y}\right)^{\prime}}=1-\frac{RSS}{TSS}\end{aligned}\]</div>
<p>and the adjusted <span class="math">\(R^{2}\)</span> is defined</p>
<div class="math">
\[\begin{aligned}
\bar{R}^{2} &amp; =1-\left(1-R^{2}\right)\frac{N-k_{c}}{N-k}.\end{aligned}\]</div>
<p>The residual variance is
<span class="math">\(s^{2}=n^{-1}\hat{\epsilon}^{\prime}\hat{\epsilon}\)</span> unless the
debiased flag is used, in which case a small sample adjusted version is
estimated
<span class="math">\(s^{2}=\left(n-k\right)^{-1}\hat{\epsilon}^{\prime}\hat{\epsilon}\)</span>.
The model degree of freedom is <span class="math">\(k\)</span> and the residual degree of
freedom is <span class="math">\(n-k\)</span>.</p>
<p>The model F-statistic is defined</p>
<div class="math">
\[\begin{aligned}
F &amp; =\hat{\beta}_{-}^{\prime}\hat{V}_{-}^{-1}\dot{\hat{\beta}_{-}}\end{aligned}\]</div>
<p>where the notation <span class="math">\(\hat{\beta}_{-}\)</span> indicates that the constant
is excluded from <span class="math">\(\hat{\beta}\)</span> and <span class="math">\(\hat{V}_{-}\)</span> indicates
that the row and column corresponding to a constant are excluded. <a class="footnote-reference" href="#id3" id="id1">[1]</a>
The test statistic is distributed as <span class="math">\(\chi_{k-k_{c}}^{2}.\)</span> If the
debiased flag is set, then the test statistic <span class="math">\(F\)</span> is transformed
as <span class="math">\(F/\left(k-k_{c}\right)\)</span> and a <span class="math">\(F_{k-k_{c},n-k}\)</span>
distribution is used.</p>
</div>
<div class="section" id="parameter-covariance-estimation">
<h2>Parameter Covariance Estimation<a class="headerlink" href="#parameter-covariance-estimation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="two-stage-ls-liml-and-k-class-estimators">
<h3>Two-stage LS, LIML and k-class estimators<a class="headerlink" href="#two-stage-ls-liml-and-k-class-estimators" title="Permalink to this headline">¶</a></h3>
<p>Four covariance estimators are available. The first is the standard
homoskedastic covariance, defined as</p>
<div class="math">
\[\begin{aligned}
\hat{\Sigma}=n^{-1}s^{2}\left(\frac{X^{\prime}\left(I-\kappa M_{z}\right)X}{n}\right)^{-1} &amp; =n^{-1}s^{2}\hat{A}.\end{aligned}\]</div>
<p>Note that this estimator can be expressed as</p>
<div class="math">
\[\begin{aligned}
\hat{\Sigma}=n^{-1}\hat{A}^{-1}\left\{ s^{2}\hat{A}\right\} \hat{A}^{-1} &amp; =n^{-1}\hat{A}^{-1}\hat{B}\hat{A}^{-1}.\end{aligned}\]</div>
<p>All estimators take this form and only differ in how the asymptotic
covariance of the scores, <span class="math">\(B\)</span>, is estimated. For the homoskedastic
covariance estimator, <span class="math">\(\hat{B}=s^{2}\hat{A}.\)</span> The score covariance
in the heteroskedasticity robust covariance estimator is</p>
<div class="math">
\[\begin{aligned}
\hat{B} &amp; =n^{-1}\sum_{i=1}^{n}\hat{\epsilon}_{i}^{2}\hat{x}_{i}\hat{x}_{i}^{\prime}=n^{-1}\sum_{i=1}^{n}\hat{\xi}_{i}\hat{\xi}_{i}^{\prime}.\end{aligned}\]</div>
<p>where <span class="math">\(\hat{x_{i}}\)</span> is row <span class="math">\(i\)</span> of <span class="math">\(\hat{X}=P_{Z}X\)</span> and
<span class="math">\(\hat{\xi}_{i}=\hat{\epsilon}_{i}\hat{x}_{i}\)</span>.</p>
<p>The kernel covariance estimator is robust to both heteroskedasticity and
autocorrelation and is defined as</p>
<div class="math">
\[\begin{split}\begin{aligned}
\hat{B} &amp; =\hat{\Gamma}_{0}+\sum_{i=1}^{n-1}K\left(\frac{i}{h}\right)\left(\hat{\Gamma}_{i}+\hat{\Gamma}_{i}^{\prime}\right)\\
\hat{\Gamma_{j}} &amp; =n^{-1}\sum_{i=j+1}^{n}\hat{\xi}_{i-j}\hat{\xi}_{i}^{\prime}\end{aligned}\end{split}\]</div>
<p>where <span class="math">\(K\left(\frac{i}{h}\right)\)</span> is a kernel weighting function
where <span class="math">\(h\)</span> is the kernel bandwidth.</p>
<p>The one-way clustered covariance estimator is defined as</p>
<div class="math">
\[\begin{aligned}
n^{-1}\sum_{j=1}^{g}\left(\sum_{i\in\mathcal{G}_{j}}\hat{\xi}_{i}\right)\left(\sum_{i\in\mathcal{G}_{j}}\hat{\xi}_{i}\right)^{\prime}\end{aligned}\]</div>
<p>where <span class="math">\(\sum_{i\in\mathcal{G}_{j}}\hat{\xi}_{i}\)</span> is the sum of the
scores for all members in group <span class="math">\(\mathcal{G}_{j}\)</span> and <span class="math">\(g\)</span> is
the number of groups.</p>
<p>If the debiased flag is used to perform a small-sample adjustment, all
estimators except the clustered covariance are rescaled by
<span class="math">\(\left(n-k\right)/n\)</span>. The clustered covariance is rescaled by
<span class="math">\(\left(\left(n-k\right)\left(n-1\right)/n^{2}\right)\left(\left(g-1\right)/g\right)\)</span>. <a class="footnote-reference" href="#id4" id="id2">[2]</a></p>
</div>
<div class="section" id="standard-errors">
<h3>Standard Errors<a class="headerlink" href="#standard-errors" title="Permalink to this headline">¶</a></h3>
<p>Standard errors are defined as</p>
<div class="math">
\[s.e.\left(\hat{\beta}_{j}\right)=\sqrt{e_{j}^{\prime}\hat{\Sigma}e_{j}}\]</div>
<p>where <span class="math">\(e_{j}\)</span> is a vector of 0s except in location <span class="math">\(j\)</span> which
is 1.</p>
</div>
<div class="section" id="t-statistics">
<h3>T-statistics<a class="headerlink" href="#t-statistics" title="Permalink to this headline">¶</a></h3>
<p>T-statistics test the null <span class="math">\(H_{0}:\beta_{j}=0\)</span> against a 2-sided
alternative and are defined as</p>
<div class="math">
\[z=\frac{\hat{\beta}_{j}}{s.e.\left(\hat{\beta}_{j}\right)}.\]</div>
</div>
<div class="section" id="p-values">
<h3>P-values<a class="headerlink" href="#p-values" title="Permalink to this headline">¶</a></h3>
<p>P-values are computes using 2-sided tests,</p>
<div class="math">
\[Pr\left(\left|z\right|&gt;Z\right)=2-2\Phi\left(\left|z\right|\right)\]</div>
<p>If the covariance estimator was debiased, a Student’s t distribution
with <span class="math">\(n-k\)</span> degrees of freedom is used,</p>
<div class="math">
\[\begin{aligned}
Pr\left(\left|z\right|&gt;Z\right) &amp; =2-2t_{n-k}\left(\left|z\right|\right)\end{aligned}\]</div>
<p>where <span class="math">\(t_{n-k}\left(\cdot\right)\)</span> is the CDF of a Student’s T
distribution.</p>
</div>
<div class="section" id="confidence-intervals">
<h3>Confidence Intervals<a class="headerlink" href="#confidence-intervals" title="Permalink to this headline">¶</a></h3>
<p>Confidence intervals are constructed as</p>
<div class="math">
\[CI_{i,1-\alpha}=\hat{\beta}_{i}\pm q_{\alpha/2}\times\hat{\sigma}_{\beta_{i}}\]</div>
<p>where <span class="math">\(q_{\alpha/2}\)</span> is the <span class="math">\(\alpha/2\)</span> quantile of a
standard Normal distribution or a Student’s t. The Student’s t is used
when a debiased covariance estimator is used.</p>
</div>
<div class="section" id="linear-hypothesis-tests">
<h3>Linear Hypothesis Tests<a class="headerlink" href="#linear-hypothesis-tests" title="Permalink to this headline">¶</a></h3>
<p>Linear hypothesis tests examine the validity of nulls of the form
<span class="math">\(H_{0}:R\beta-r=0\)</span> and are implemented using a Wald test statistic</p>
<div class="math">
\[W=\left(R\hat{\beta}-r\right)^{\prime}\left[R^{\prime}\hat{\Sigma}R\right]^{-1}\left(R\hat{\beta}-r\right)\sim\chi_{q}^{2}\]</div>
<p>where <span class="math">\(q\)</span> is the <span class="math">\(rank\left(R\right)\)</span> which is usually the
number of rows in <span class="math">\(R\)</span> . If the debiased flag is used, then
<span class="math">\(W/q\)</span> is reported and critical and p-values are taken from a
<span class="math">\(F_{q,n-k}\)</span> distribution.</p>
</div>
<div class="section" id="gmm-covariance-estimators">
<h3>GMM Covariance estimators<a class="headerlink" href="#gmm-covariance-estimators" title="Permalink to this headline">¶</a></h3>
<p>GMM covariance depends on the weighting matrix used in estimation and
the assumed covariance of the scores. In most applications these are the
same and so the inefficient form,</p>
<div class="math">
\[\hat{\Sigma}=n^{-1}\left(\left(\frac{X'Z}{n}\right)W\left(\frac{Z'X}{n}\right)\right)^{-1}\left(\left(\frac{X'Z}{n}\right)WSW\left(\frac{Z'X}{n}\right)\right)\left(\left(\frac{X'Z}{n}\right)W\left(\frac{Z'X}{n}\right)\right)^{-1}\]</div>
<p>will collapse to the simpler form</p>
<div class="math">
\[\hat{\Sigma}=n^{-1}\left(\left(\frac{X'Z}{n}\right)W\left(\frac{Z'X}{n}\right)\right)^{-1}\]</div>
<p>when <span class="math">\(W=S^{-1}\)</span>. When an unadjusted (homoskedastic) covariance is
used,</p>
<div class="math">
\[\hat{S}=\tilde{s}^{2}n^{-1}\sum_{j=1}^{n}z_{j}^{\prime}z_{j}\]</div>
<p>where
<span class="math">\(\tilde{s}^{2}=n^{-1}\sum_{i=1}^{n}\left(\epsilon_{i}-\bar{\epsilon}\right)^{2}\)</span>
subtracts the mean which may be non-zero if the model is overidentified.
Like previous covariance estimators, if the debiased flag is used,
<span class="math">\(n^{-1}\)</span> is replaced by <span class="math">\(\left(n-k\right)^{-1}\)</span>. When a
robust (heteroskedastic) covariance is used, the estimator of <span class="math">\(S\)</span>
is modified to</p>
<div class="math">
\[\hat{S}=n^{-1}\sum_{i=1}^{n}\hat{\epsilon}_{i}^{2}z_{i}^{\prime}z_{i}.\]</div>
<p>If the debiased flag is used, <span class="math">\(n^{-1}\)</span> is replaced by
<span class="math">\(\left(n-k\right)^{-1}\)</span>.</p>
<p>Kernel covariance estimators of <span class="math">\(S\)</span> take the form</p>
<div class="math">
\[\begin{split}\begin{aligned}
\hat{S} &amp; =\hat{\Gamma}_{0}+\sum_{i=1}^{n-1}k\left(i/h\right)\left(\hat{\Gamma}_{i}+\hat{\Gamma}_{i}^{\prime}\right)\\
\hat{\Gamma_{j}} &amp; =n^{-1}\sum_{i=j+1}^{n}\hat{\epsilon}_{i-j}\hat{\epsilon}_{i}z_{i-j}^{\prime}z_{i}\end{aligned}\end{split}\]</div>
<p>and <span class="math">\(k\left(\cdot\right)\)</span> is a kernel weighting function with
bandwidth <span class="math">\(h\)</span>. If the debiased flag is used, <span class="math">\(n^{-1}\)</span> is
replaced by <span class="math">\(\left(n-k\right)^{-1}\)</span>.</p>
<p>The one-way clustered covariance estimator is defined as</p>
<div class="math">
\[\hat{S}=n^{-1}\sum_{j=1}^{g}\left(\sum_{i\in\mathcal{G}_{j}}\hat{\epsilon}_{i}z_{i}\right)^{\prime}\left(\sum_{i\in\mathcal{G}_{j}}\hat{\epsilon}_{i}z_{i}\right)\]</div>
<p>where <span class="math">\(\sum_{i\in\mathcal{G}_{j}}\hat{\epsilon}_{i}z_{i}\)</span> is the
sum of the moment conditional for all members in group
<span class="math">\(\mathcal{G}_{j}\)</span> and <span class="math">\(g\)</span> is the number of groups. If the
debiased flag is used, the <span class="math">\(n^{-1}\)</span> term is replaced by</p>
<div class="math">
\[\left(n-k\right)^{-1}\frac{n-1}{n}\frac{g}{g-1}.\]</div>
</div>
<div class="section" id="gmm-weight-estimators">
<h3>GMM Weight Estimators<a class="headerlink" href="#gmm-weight-estimators" title="Permalink to this headline">¶</a></h3>
<p>The GMM optimal weight estimators are identical to the the estimators of
<span class="math">\(S\)</span> with two notable exceptions. First, they are never debiased
and so always use <span class="math">\(n^{-1}\)</span>. Second, if the center flag is true,
the demeaned moment conditions defined as
<span class="math">\(\tilde{g}_{i}=z_{i}\hat{\epsilon}_{i}-\overline{z\epsilon}\)</span> are
used in-place of <span class="math">\(g_{i}\)</span> in the robust, kernel and clustered
estimators. The unadjusted estimator is always centered, and so this
option has no effect.</p>
</div>
</div>
<div class="section" id="post-estimation">
<h2>Post-estimation<a class="headerlink" href="#post-estimation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="sls-and-liml-post-estimation-results">
<h3>2SLS and LIML Post-estimation Results<a class="headerlink" href="#sls-and-liml-post-estimation-results" title="Permalink to this headline">¶</a></h3>
<p><strong>Sargan</strong></p>
<p>Sargan’s test of over-identifying restrictions examines whether the
variance of the IV residuals is similar to that of the OLS residuals.
The test statistic is computed</p>
<div class="math">
\[s=n(1-\hat{\epsilon}^{\prime}M_{Z}\hat{\epsilon}/\hat{\epsilon}^{\prime}\hat{\epsilon})\sim\chi_{v}^{2}\]</div>
<p>where <span class="math">\(\hat{\epsilon}\)</span> are the IV residuals and <span class="math">\(M_{Z}\)</span> is
the annihilator matrix using all exogenous variables.<span class="math">\(\nu\)</span> is
the number of overidentifying restrictions, which is the number of
instruments minus the number of endogenous variables, <span class="math">\(p-k_{2}\)</span>.</p>
<p><strong>Basmann</strong></p>
<p>Basmann’s test is a small-sample corrected version of Sargan’s test of
over-identifying restrictions. It has the same distribution. Let
<span class="math">\(s\)</span> be Sargan’s test statistic, then Basmann’s test statistic is</p>
<div class="math">
\[s(n-p)/(n-s)\sim\chi_{v}^{2}\]</div>
<p><strong>Wooldridge score</strong></p>
<p>Wooldridge’s score test of exogeneity examines the magnitude of the
correlation between the OLS residuals and a an appropriately constructed
set of residuals of the instruments. Define <span class="math">\(e=M_{X}Y\)</span> and
<span class="math">\(\nu=M_{X}M_{Z}X_{2}\)</span>. Then the test statistic is computed from
the regression</p>
<div class="math">
\[1=\gamma_{1}\hat{\epsilon}_{1}\hat{v}_{1,i}+\ldots+\gamma_{p}\hat{\epsilon}_{1}\hat{v}_{p,i}+\eta_{i}\]</div>
<p>as <span class="math">\(nR^{2}\sim\chi_{k_{2}}^{2}\)</span>.</p>
<p><strong>Wooldridge regression</strong></p>
<p>Wooldridge’s regression test of exogeneity is closely related to the
score test and is generally more powerful. It also inherits robustness
to heteroskedasticity and/or autocorrelation the comes from the choice
of covariance estimator used in the model. Define <span class="math">\(R=M_{Z}X_{2}\)</span>.
The test is implemented in a regression of</p>
<div class="math">
\[Y=X\beta+R\gamma+\eta\]</div>
<p>as</p>
<div class="math">
\[\hat{\gamma}^{\prime}\hat{\Sigma}_{\gamma}^{-1}\gamma^{\prime}\sim\chi_{k_{2}}^{2}\]</div>
<p>where <span class="math">\(\hat{\Sigma}_{\gamma}\)</span> is the block of the covariance
matrix corresponding to the <span class="math">\(\gamma\)</span> parameters.
<span class="math">\(\hat{\Sigma}\)</span> is estimated using the same covariance estimator as
the model fit.</p>
<p><strong>Wooldridge’s Test of Overidentifying restrictions</strong></p>
<p>Wooldridge’s test is a score test examining whether the component of the
instrument that is uncorrelated with both the included exogenous and the
fitted exogenous is uncorrelated with the IV residuals. Define
<span class="math">\(\tilde{Z}=M_{\left[X_{1}\:\hat{X}_{2}\right]}Z_{2,1:q}\)</span> where
<span class="math">\(\hat{X_{2}}\)</span> are the fitted values from the first stage
regression of the endogenous on all exogenous variables and
<span class="math">\(Z_{2,1:q}\)</span> contains any <span class="math">\(q\)</span> columns of <span class="math">\(Z_{2}\)</span>,
<span class="math">\(q=p-k_{2}\)</span> . The test statistic is computed using a regression of
1s on the test functions <span class="math">\(\hat{\epsilon}_{i}\tilde{z}_{i,j}\)</span> for
<span class="math">\(j=1,\ldots,q\)</span> which should have expected value 0.</p>
<div class="math">
\[1=\gamma_{1}\hat{\epsilon}_{i}\tilde{z}_{i,1}+\ldots+\gamma_{q}\hat{\epsilon}_{i}\tilde{z}_{i,q}\]</div>
<p>The test statistic is <span class="math">\(nR^{2}\sim\chi_{q}^{2}\)</span> from the
regression.</p>
<p><strong>Anderson-Rubin</strong></p>
<p>The Andersen-Rubin test of overidentification examines the magnitude of
the LIML <span class="math">\(\hat{\kappa}\)</span>which should be close to unity when the
model is not overidentified.</p>
<div class="math">
\[n\ln(\hat{\kappa})\sim\chi_{q}^{2}\]</div>
<p>where <span class="math">\(q=p-k_{2}\)</span>.</p>
<p><strong>Basman’s F</strong></p>
<p>Banmann’s F test of overidentification also examines the magnitude of
the LIML <span class="math">\(\hat{\kappa}\)</span>. The test statistic is</p>
<div class="math">
\[\hat{\kappa}(n-p)/q\sim F_{q,n-n_{instr}}\]</div>
<p>where <span class="math">\(q=p-k_{2}\)</span>.</p>
<p><strong>Durbin and Wu-Haussman</strong></p>
<p>Durbin’s and the Wu-Hausmann tests of exogeneity test of exogeneity is
depends on the variance of the residuals when come endogenous variables
are treated as exogenous against the case where they are treated as
endogenous. Durbin’s test statistic is</p>
<div class="math">
\[\begin{split}\begin{aligned}
\delta= &amp; \hat{\epsilon}'_{e}P_{[z,w]}\hat{\epsilon}_{e}-\hat{\epsilon}'_{c}P_{z}\hat{\epsilon}_{c}\\
D= &amp; \delta/(\hat{\epsilon}'_{e}\hat{\epsilon}_{e})/n\sim\chi_{q}^{2}\end{aligned}\end{split}\]</div>
<p>and the Wu-Hausmann test statistic is</p>
<div class="math">
\[\begin{aligned}
WH= &amp; \frac{\delta/q}{(\hat{\epsilon}'_{e}\hat{\epsilon}_{e}-\delta)/v}\sim F_{q,\nu}\end{aligned}\]</div>
<p>where <span class="math">\(\hat{\epsilon}_{e}\)</span> treats the selected set of endogenous
variables as exogenous (efficient estimate) and
<span class="math">\(\hat{\epsilon}_{c}\)</span> is a consistent estimator if these variables
are endogenous.<span class="math">\(P_{\left[Z\,W\right]}\)</span> is the projection matrix
containing all exogenous variables including the instrument as well as
the variables being tested for endogeneity
<span class="math">\(\left(W\right)\)</span>.<span class="math">\(q\)</span> is the number of variables being
tested for exogeneity and <span class="math">\(\nu=n-k1-k2-q\)</span>.</p>
</div>
<div class="section" id="gmm-post-estimation-results">
<h3>GMM Post-estimation Results<a class="headerlink" href="#gmm-post-estimation-results" title="Permalink to this headline">¶</a></h3>
<p><strong>J-stat</strong></p>
<p>The J-statistic tests whether the model is over-identified, and is
defined</p>
<div class="math">
\[n\bar{g}'W^{-1}\bar{g}\sim\chi_{q}^{2}\]</div>
<p>where <span class="math">\(\bar{g}=n^{-1}\sum\hat{\epsilon}_{i}z_{i}\)</span> and <span class="math">\(W\)</span> is
a consistent estimator of the variance of <span class="math">\(\sqrt{n}\bar{g}\)</span>. The
degree of freedom is <span class="math">\(q=p-k_{2}\)</span>.</p>
<p><strong>C-stat</strong></p>
<p>The C-statistic tests exogeneity by treating a the set of endogenous
variables as exogenous. In practice this means that are included in the
GMM moment conditions, and so a likelihood-ratio-like test statistic can
be computed as</p>
<div class="math">
\[J_{e}-J_{c}\sim\chi_{m}^{2}\]</div>
<p>where <span class="math">\(J_{e}\)</span> is the J-statistic treating the tested variables as
exogenous and <span class="math">\(J_{c}\)</span> leaves then as endogenous. The optimal
weighting matrix is computed from the expanded model (efficient) and
used to estimate parameters in both models. This ensures that the test
statistic is positive.</p>
</div>
</div>
<div class="section" id="first-stage-estimation-analysis">
<h2>First-stage Estimation Analysis<a class="headerlink" href="#first-stage-estimation-analysis" title="Permalink to this headline">¶</a></h2>
<p><strong>Partial R2 and Partial F-statistic</strong></p>
<p>The <span class="math">\(R^{2}\)</span> is reported after orthogonalizing the instruments from
included exogenous variables, so that the model estimated is</p>
<div class="math">
\[x_{2i}=\gamma_{0}+\tilde{z}_{2i}\gamma+\eta_{i}\]</div>
<p>where <span class="math">\(\tilde{Z}_{2}=M_{X_{1}}\tilde{Z}\)</span>. The partial
<span class="math">\(F\)</span>-statistic is the F-statistic from this regression. It is
implemented as a standard <span class="math">\(F\)</span>-statistic when the data is assumed
to be homoskedastic with an <span class="math">\(F_{p_{2},n-p_{2}}\)</span> distribution. In
all other cases, a quadratic form is used with an asymptotic
<span class="math">\(\chi_{p_{2}}^{2}\)</span> distribution testing <span class="math">\(H_{0}:\gamma=0\)</span>.</p>
<p><strong>Shea’s R2</strong></p>
<p>Shea’s <span class="math">\(R^{2}\)</span> is defined as the ratio of the parameter variances
under OLS and 2SLS estimation standardized by the unexplained variance
under each,</p>
<div class="math">
\[\frac{\frac{\hat{\sigma}_{OLS,\beta_{i}}^{2}}{1-R_{OLS}^{2}}}{\frac{\hat{\sigma}_{IV,\beta_{i}}^{2}}{1-R_{IV}^{2}}}=\frac{\hat{\sigma}_{OLS,\beta_{i}}^{2}}{\hat{\sigma}_{IV,\beta_{i}}^{2}}\times\frac{1-R_{IV}^{2}}{1-R_{OLS}^{2}}\]</div>
<p>If the estimator under 2SLS was as good as under OLS, both ratios would
be 1 and Shea’s <span class="math">\(R^{2}=1\)</span>. On the other hand, the worse the
<span class="math">\(IV\)</span> fit in terms of either <span class="math">\(R^{2}\)</span> or the parameter
variances, the lower the value reported by Shea’s <span class="math">\(R^{2}\)</span>.</p>
</div>
<div class="section" id="kernel-weights-and-bandwidth-selection">
<h2>Kernel Weights and Bandwidth Selection<a class="headerlink" href="#kernel-weights-and-bandwidth-selection" title="Permalink to this headline">¶</a></h2>
<p><strong>Kernel weights</strong></p>
<p>In all formulas, <span class="math">\(m\)</span> is the kernel bandwidth parameter.</p>
<ul>
<li><p class="first">Bartlett</p>
<div class="math">
\[w_{i}=1-\frac{i}{m+1},\,i&lt;m\]</div>
</li>
<li><p class="first">Parzen</p>
<div class="math">
\[\begin{split}\begin{aligned}
z_{i} &amp; =\frac{i}{m+1},\,i&lt;m\\
w_{i} &amp; =1-6z_{i}^{2}+6z_{i}^{3},z\leq0.5\\
w_{i} &amp; =2(1-z_{i})^{3},z&gt;0.5\end{aligned}\end{split}\]</div>
</li>
<li><p class="first">Quadratic-Spectral</p>
<div class="math">
\[\begin{split}\begin{aligned}
z_{i} &amp; =\frac{6\pi i}{5m}\\
w_{0} &amp; =1\\
w_{i} &amp; =3(\sin(z_{i})/z_{i}-\cos(z_{i}))/z_{i}^{2},\:i\geq1\end{aligned}\end{split}\]</div>
</li>
</ul>
<p><strong>Optimal BW selection</strong></p>
<p>TODO</p>
</div>
<div class="section" id="constant-detection">
<h2>Constant Detection<a class="headerlink" href="#constant-detection" title="Permalink to this headline">¶</a></h2>
<p>Whether a model contains a constant or equivalent is tested using three
tests. These are executed in order and so once a constant is detected,
the others are not executed. The simplest method to ensure that a
constant is correctly detected is to include a columns of 1s.</p>
<ol class="arabic simple">
<li>A column with only 1.0s</li>
<li>A column with a maximum minus minimum equal to 0 and that is not all
0s.</li>
<li>Whether the rank of <span class="math">\(X\)</span> is the same as
<span class="math">\(\left[1_{N}\:X\right]\)</span>. If these are the same, then the model
contains a constant equivalent (e.g., dummies for all categories).</li>
</ol>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>If the model contains an implicit constant, e.g., all categories of a
dummy, one of the categories is excluded when computing the test
statistic. The choice of category to drop has no effect and is
equivalent to reparameterizing the model with a constant and
excluding one category of dummy.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td>This somewhat non-obvious choice is driven by Stata compatibility.</td></tr>
</tbody>
</table>
<p class="rubric">References</p>
<p>Sources used in writing the code include <a class="reference internal" href="../references.html#baltagi" id="id5">[Baltagi]</a>, <a class="reference internal" href="../references.html#baumetal" id="id6">[BaumEtAl]</a> and <a class="reference internal" href="../references.html#cametal" id="id7">[CamEtAl]</a>,
<a class="reference internal" href="../references.html#camtri05" id="id8">[CamTri05]</a>, <a class="reference internal" href="../references.html#camtri09" id="id9">[CamTri09]</a>, <a class="reference internal" href="../references.html#greene" id="id10">[Greene]</a>, <a class="reference internal" href="../references.html#newwes94" id="id11">[NewWes94]</a>, <a class="reference internal" href="../references.html#stata" id="id12">[Stata]</a>, <a class="reference internal" href="../references.html#wool10" id="id13">[Wool10]</a> and <a class="reference internal" href="../references.html#wool12" id="id14">[Wool12]</a>.</p>
</div>
</div>


          </div>
            
  <div class="footer-relations">
    
      <div class="pull-left">
        <a class="btn btn-default" href="gmm.html" title="previous chapter (use the left arrow)">GMM Weight and Covariance Estimation</a>
      </div>
    
      <div class="pull-right">
        <a class="btn btn-default" href="../panel/index.html" title="next chapter (use the right arrow)">Panel Data Model Estimation</a>
      </div>
    </div>
    <div class="clearer"></div>
  
        </div>
        <div class="clearfix"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../panel/index.html" title="Panel Data Model Estimation"
             >next</a> |</li>
        <li class="right" >
          <a href="gmm.html" title="GMM Weight and Covariance Estimation"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">linearmodels 3.5+15.gd85af6a documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >Instrumental Variable Estimation</a> &#187;</li> 
      </ul>
    </div>
<script type="text/javascript">
  $("#mobile-toggle a").click(function () {
    $("#left-column").toggle();
  });
</script>
<script type="text/javascript" src="../_static/js/bootstrap.js"></script>
  <div class="footer">
    &copy; Copyright 2017, Kevin Sheppard. Created using <a href="http://sphinx.pocoo.org/">Sphinx</a>.
  </div>
  </body>
</html>